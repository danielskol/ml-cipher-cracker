{
 "metadata": {
  "name": "",
  "signature": "sha256:f8e67ebf76d91932a4f4ec6e86bb079d9bb3076e068f3cedf97b82d380b3c405"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "read text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_text_words(filename, wordsnumber):\n",
      "    X = list()\n",
      "    with open(filename) as f:\n",
      "        for i in xrange(wordsnumber):\n",
      "            line = f.readline()\n",
      "            if not line:\n",
      "                print 'reached end of file'\n",
      "                break            \n",
      "            X.append(line)     \n",
      "    X = ''.join(X) \n",
      "    X = X.replace('\\n', '{') #123\n",
      "    return X\n",
      "\n",
      "def read_text_whole(filename):\n",
      "    with open(filename) as f:\n",
      "        X = f.read()    \n",
      "    X = X.replace('\\n', '{') #123\n",
      "    return X\n",
      "\n",
      "def chop_text_to_size(text, size):\n",
      "    return text[:1024*1024*size]\n",
      "\n",
      "def read_text_filesize(filename, size):\n",
      "    with open(filename) as f:\n",
      "        X = f.read(1024*1024*size)\n",
      "    X = X.replace('\\n', '{') #123\n",
      "    return X    \n",
      "\n",
      "text = read_text_filesize('main\\war_and_peace.txt', 3)\n",
      "print len(text)\n",
      "print text[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3111644\n",
        "the{projec\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_text = read_text_words('main\\oliver_twist.txt', 7000)\n",
      "# for i in xrange(10):\n",
      "#     print test_text[i]\n",
      "print len(test_text)\n",
      "print test_text[:15]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "38141\n",
        "\ufeffthe{project{\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "length = 575514\n",
      "train_text = read_text_words('main\\war_and_peace.txt', length)\n",
      "# print train_text[575513]\n",
      "print train_text[:15]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "the{project{gut\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "unigram statistics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from __future__ import division\n",
      "def get_unigram_stats(text):\n",
      "    length = len(text)\n",
      "    stats = np.zeros(27)\n",
      "    for i in xrange(length):\n",
      "        c = ord(text[i])\n",
      "#         print text[i]\n",
      "        stats[c-97]+=1\n",
      "        #97-122, 123 - word delimiter  \n",
      "    delimcount = stats[26]\n",
      "    stats = stats[:26]\n",
      "    return stats/(length-delimcount)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stats = get_unigram_stats(train_text)\n",
      "print sum(stats)\n",
      "print stats\n",
      "# print (np.argmax(stats))\n",
      "# print chr(4+97)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1.0\n",
        "[  7.39113459e-02   1.81305456e-02   2.06821066e-02   3.73550425e-02\n",
        "   1.35326174e-01   2.11409947e-02   1.72996665e-02   6.27944681e-02\n",
        "   6.73202599e-02   4.64244817e-05   9.12895769e-03   4.52049462e-02\n",
        "   2.86462859e-02   6.20385823e-02   8.21028862e-02   1.52540133e-02\n",
        "   9.76104486e-04   6.32206210e-02   6.18939522e-02   8.58275580e-02\n",
        "   3.83424555e-02   3.96334132e-03   2.41907261e-02   1.02371934e-03\n",
        "   2.38104024e-02   3.68419925e-04]\n",
        "4\n",
        "e\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "counts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_unicount(text):\n",
      "    length = len(text)\n",
      "    counts = np.zeros(27)\n",
      "    for i in xrange(length):\n",
      "        c = ord(text[i])\n",
      "        counts[c-97]+=1\n",
      "        #97-122, 123 - word delimiter    \n",
      "    return counts[:26]\n",
      "counts = get_unicount(train_text)\n",
      "print counts\n",
      "# print chr(np.argmax(counts)+97)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 518305.  113684.  165626.  271591.  886827.  152173.  125299.  429434.\n",
        "  456822.    5105.   55261.  286239.  185267.  446899.  533060.  111999.\n",
        "    7130.  415610.  427365.  609987.  225422.   46685.  157447.    9380.\n",
        "  142848.    2767.]\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "bigram statistics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "array"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_bigram_stats_array(text):        \n",
      "    length = len(text)\n",
      "    stats = np.zeros((27,27))\n",
      "    for i in xrange(length-1):\n",
      "        c = ord(text[i])\n",
      "        d = ord(text[i+1])\n",
      "        stats[c-97, d-97]+=1\n",
      "        #97-122, 123 - word delimiter  \n",
      "    stats = stats[:26]\n",
      "    for i in xrange(26):        \n",
      "        stats[i] = stats[i]/counts[i]\n",
      "    return stats[:26,:26]\n",
      "\n",
      "stats = get_bigram_stats_array(train_text)\n",
      "# print stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print np.amax(stats, 1)\n",
      "print np.amax(stats)\n",
      "print np.argmax(stats)\n",
      "print chr(436//26+97)\n",
      "print chr(436 - 26*(436//26) +97)\n",
      "print np.count_nonzero(stats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.965243902439\n",
        "436\n",
        "q\n",
        "u\n",
        "519\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit get_bigram_stats_array(train_text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 3.02 s per loop\n"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "dict"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_bigram_stats_dic(text):        \n",
      "    length = len(text)\n",
      "    dic = {}\n",
      "    for i in xrange(length-1):\n",
      "        if ord(text[i]) == 123 or ord(text[i+1]) == 123:\n",
      "            continue            \n",
      "        if (text[i], text[i+1]) in dic:\n",
      "            dic[(text[i], text[i+1])] += 1\n",
      "        else: \n",
      "            dic[(text[i], text[i+1])] = 1 \n",
      "            \n",
      "    for k,v in dic.items():\n",
      "        dic[k] = v/counts[ord(k[0])-97]\n",
      "    return dic\n",
      "\n",
      "d = get_bigram_stats_dic(train_text)\n",
      "# print d\n",
      "import operator\n",
      "print max(d.iteritems(), key=operator.itemgetter(1))[0]\n",
      "print len(d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('q', 'u')\n",
        "591\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit get_bigram_stats_dic(train_text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1 loops, best of 3: 1.19 s per loop\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "TODO zip "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Quality measurement:\n",
      "$$ r(x, y, f) = \\frac{\\sum^{|x|}_{i=1} I[f(x_i) = y_i]}{|x|}$$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Don\u2019t forget to average over several restarts of Metropolis algorithm since finite-size samples produced by it depend on the initialization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def quality(decrypted, original):\n",
      "    l = len(decrypted)\n",
      "    zipped = zip(decrypted, original)    \n",
      "    return sum(1 for x,y in zipped if x != y)/l\n",
      "    \n",
      "    \n",
      "quality('abcd','adrd')\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 66,
       "text": [
        "0.5"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "crypt"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "from numpy.random import rand\n",
      "\n",
      "def crypt(text):\n",
      "    p = range(26)\n",
      "    random.shuffle(p)\n",
      "    output=''\n",
      "    for ch in text:\n",
      "            try:\n",
      "                x = ord(ch) - ord('a')\n",
      "                output+=(chr(p[x] + ord('a')))\n",
      "            except:\n",
      "                pass\n",
      "#                 print '{} unsupported'.format(ch)\n",
      "    for i in xrange(len(p)):\n",
      "        print '{} -> {}'.format(chr(ord('a') + i), chr(ord('a') + p[i]))\n",
      "     \n",
      "    return output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Varying size of training text"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fix large (e.g. 5000 or more words) encrypted text and explore how the ratio of correctly decrypted symbols\n",
      "depends on the size of training text (using the same number of MCMC iterations)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Encryption"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = 'main\\oliver_twist.txt'\n",
      "test_text = read_text_words(fname, 7000)\n",
      "#NB remove word delimiters { before encryption!\n",
      "original = test_text.replace('{','')\n",
      "#encryption\n",
      "encrypted = crypt(original)\n",
      "print encrypted[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "a -> r\n",
        "b -> e\n",
        "c -> c\n",
        "d -> z\n",
        "e -> j\n",
        "f -> m\n",
        "g -> f\n",
        "h -> w\n",
        "i -> b\n",
        "j -> o\n",
        "k -> s\n",
        "l -> u\n",
        "m -> y\n",
        "n -> g\n",
        "o -> d\n",
        "p -> h\n",
        "q -> a\n",
        "r -> q\n",
        "s -> i\n",
        "t -> l\n",
        "u -> t\n",
        "v -> n\n",
        "w -> p\n",
        "x -> v\n",
        "y -> k\n",
        "z -> x\n",
        "lwjhqdojclftljgejqfj\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "stats, metropolis, decrypt, quality, plot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "\n",
      "sizes =  [2,4,8,16]\n",
      "for s in sizes:   \n",
      "    i=0\n",
      "    train_text = read_text_filesize('main\\super.txt', s)\n",
      "    unistats = get_unigram_stats(train_text)\n",
      "    counts = get_unicount(train_text)\n",
      "    bistats = get_bigram_stats_dic(train_text)\n",
      "#     print chr(np.argmax(counts)+97)\n",
      "#     print max(bistats.iteritems(), key=operator.itemgetter(1))[0]\n",
      "    \n",
      "    #Metropolis here\n",
      "    #decryption\n",
      "    #output - decrypted text\n",
      "#     qs = np.zeros(len(sizes))\n",
      "#     qs[i] = quality(decrypted, original)\n",
      "#     i+=1\n",
      "\n",
      "print train_text[:1000]\n",
      "# plt.plot(sizes, qs) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "project{gutenberg{s{etext{of{shakespeare{s{first{folio{plays{this{is{our{rd{edition{of{most{of{these{plays{see{the{index{copyright{laws{are{changing{all{over{the{world{be{sure{to{check{the{copyright{laws{for{your{country{before{posting{these{files{please{take{a{look{at{the{important{information{in{this{header{we{encourage{you{to{keep{this{file{on{your{own{disk{keeping{an{electronic{path{open{for{the{next{readers{do{not{remove{this{welcome{to{the{world{of{free{plain{vanilla{electronic{texts{etexts{readable{by{both{humans{and{by{computers{since{these{etexts{prepared{by{hundreds{of{volunteers{and{donations{information{on{contacting{project{gutenberg{to{get{etexts{and{further{information{is{included{below{we{need{your{donations{the{first{folio{lsb{plays{rsb{by{william{shakespeare{july{lsb{etext{rsb{project{gutenberg{s{etext{of{shakespeare{s{first{folio{plays{this{file{should{be{named{wstxt{or{ws{zip{corrected{editions{of{our{etexts{get{a{new{number{wstxt{versions{based{on{separate{sources{\n"
       ]
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Varying size of test text"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Fix large (e.g. 3 MB of raw text) training text and explore how the ratio of correctly decrypted symbols depends\n",
      "on the size of observed encrypted text (using the same number of MCMC iterations as in step 2).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fname = 'main\\oliver_twist.txt'\n",
      "sizes =  [1000,10000,100000]\n",
      "for s in sizes:       \n",
      "    test_text = read_text_words(fname, s)\n",
      "    #NB remove word delimiters { before encryption!\n",
      "    original = test_text.replace('{','')\n",
      "    #encryption\n",
      "    encrypted = crypt(original)\n",
      "    \n",
      "    i=0\n",
      "    train_text = read_text_whole('main\\war_and_peace.txt')\n",
      "    unistats = get_unigram_stats(train_text)\n",
      "    counts = get_unicount(train_text)\n",
      "    bistats = get_bigram_stats_dic(train_text)\n",
      "#     print chr(np.argmax(counts)+97)\n",
      "#     print max(bistats.iteritems(), key=operator.itemgetter(1))[0]\n",
      "    \n",
      "    #Metropolis here\n",
      "    #decryption\n",
      "    #output - decrypted text\n",
      "#     qs = np.zeros(len(sizes))\n",
      "#     qs[i] = quality(decrypted, original)\n",
      "#     i+=1\n",
      "\n",
      "print train_text[:500]\n",
      "# plt.plot(sizes, qs) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "a -> n\n",
        "b -> z\n",
        "c -> a\n",
        "d -> q\n",
        "e -> o\n",
        "f -> h\n",
        "g -> g\n",
        "h -> u\n",
        "i -> p\n",
        "j -> f\n",
        "k -> i\n",
        "l -> w\n",
        "m -> r\n",
        "n -> b\n",
        "o -> v\n",
        "p -> l\n",
        "q -> m\n",
        "r -> j\n",
        "s -> d\n",
        "t -> c\n",
        "u -> e\n",
        "v -> x\n",
        "w -> k\n",
        "x -> t\n",
        "y -> s\n",
        "z -> y\n",
        "e"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('q', 'u')\n",
        "a -> h\n",
        "b -> k\n",
        "c -> r\n",
        "d -> d\n",
        "e -> y\n",
        "f -> v\n",
        "g -> u\n",
        "h -> x\n",
        "i -> c\n",
        "j -> s\n",
        "k -> g\n",
        "l -> f\n",
        "m -> o\n",
        "n -> j\n",
        "o -> i\n",
        "p -> n\n",
        "q -> m\n",
        "r -> a\n",
        "s -> p\n",
        "t -> l\n",
        "u -> z\n",
        "v -> b\n",
        "w -> t\n",
        "x -> w\n",
        "y -> q\n",
        "z -> e\n",
        "e"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('q', 'u')\n",
        "a -> b"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "b -> m\n",
        "c -> j\n",
        "d -> i\n",
        "e -> c\n",
        "f -> k\n",
        "g -> u\n",
        "h -> y\n",
        "i -> l\n",
        "j -> x\n",
        "k -> w\n",
        "l -> f\n",
        "m -> d\n",
        "n -> a\n",
        "o -> z\n",
        "p -> v\n",
        "q -> p\n",
        "r -> o\n",
        "s -> t\n",
        "t -> g\n",
        "u -> s\n",
        "v -> q\n",
        "w -> n\n",
        "x -> h\n",
        "y -> e\n",
        "z -> r\n",
        "e"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('q', 'u')\n",
        "the{project{gutenberg{ebook{of{war{and{peace{by{leo{tolstoy{this{ebook{is{for{the{use{of{anyone{anywhere{at{no{cost{and{with{almost{no{restrictions{whatsoever{you{may{copy{it{give{it{away{or{reuse{it{under{the{terms{of{the{project{gutenberg{license{included{with{this{ebook{or{online{at{wwwgutenbergorg{title{war{and{peace{author{leo{tolstoy{translators{louise{and{aylmer{maude{posting{date{january{lsb{ebook{rsb{last{updated{march{language{english{start{of{this{project{gutenberg{ebook{war{and{peace\n"
       ]
      }
     ],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}